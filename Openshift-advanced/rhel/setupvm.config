#! /bin/bash
# Some automation to setting up an advanced installation
# of OCP running on RHEL

# HOSTENV = rhel, centos, fedora
# SETUP_TYPE -
#             k8-dev - stand-alone k8 setup for local-up-cluster.sh or kube-up.sh environment
#             cnv-dev - all in one openstack/cinder/ceph and K8
#             cnv-cinder - just cinder node
#             cnv-ceph - just ceph node
#             cnv-k8 - just k8 node for local-up-cluster.sh
#             cnv-cinder-k8 - cinder and k8 on same node
#             cnv-ceph-k8 - ceph and k8 on same node
#             cnv-k8-existing - install just k8 on existing node (either the ceph or cinder)
# CINDERHOST  - the internal dnshostname of the instance (i.e. ip-172-18-8-187.ec2.internal)
# CEPHHOST    - the internal dnshostname of the instance (i.e. ip-172-18-8-187.ec2.internal)
# BLOCKPREFIX - AWS = "xv"
# GOVERSION   - 1.6, 1.7, 1.8.3, 1.8.5, 1.9.2 or yum means install golang from yum and attached repos typically will get the latest OCP version needed
# DOCKERVER   - version # (i.e.  1.12.6)
#             - "default" OR "" (installs what comes from normal enabled repos via yum)
#             - "ce" - installs latest CentOS CE version (i.e. 18.22.1)
# ETCD_VER    - version # you want installed (i.e. "3.2.14")
# ISCLOUD = aws, gce, vsphere or local (local is generally fine unless you really want to perform cloud functions for the specific provider)
# AWSKEY = the key value (only needed for AWS)
# AWSSECRET = the secret key value (only needed for AWS)
# ZONE = aws or gce zone (i.e. us-east-1d for AWS or us-east1-d for GCE)
# GCE_NUM_NODES = default num of nodes you want when running kube-up.sh for GCE.
#
# KUBEWORKDIR=(optional) centralized working directory for Kube (default is home directory of user)
# SOURCEDIR=(optonal) where GOPATH and cloned source repositories will live (default is home directory of user)
# SKIPSOURCECLONE=yes or no - yes means that you will not clone any source repos, no is default and will clone source repos - use no to save network i/o and time, if not needed
# FEATURE_GATES=This sets up an env variable for Feature Gate support (FEATURE_GATES=BlockVolumeSupport=true)
#     i.e.  here is an example of how to enable localPersistentVolume + BlockVolume Support
#
#                  export FEATURE_GATES=BlockVolumeSupport=true,PersistentLocalVolumes=true,LocalStorageCapacityIsolation=true,MountPropagation=true
#




# Control Parameters
RERUN=N

# RHSM Parameters
RHNUSER=rhn-support-account
RHNPASS=rhn-password
POOLID="8a85f9833e1404a9013e3cddf99305e6"

# Base Parameters
HOSTENV=rhel
APP_TYPE=origin
SETUP_TYPE=ansible
SKIPSUBSCRIBE=N
SKIPREPOS=Y
GOVERSION="1.10.2"
DOCKERVER="1.13.1"
ETCD_VER="3.2.18"
OCPVERSION="3.10"
ENABLE_CNS=N

#Cloud Provider Env Vars
ISCLOUD=local
AWSKEY=local
AWSSECRET=local
ZONE=us-east-1d

# Workspace Env Vars
ORIGINWORKDIR="/etc/openshift-dev"
KUBEWORKDIR="/etc/kubernetes-dev"
SOURCEDIR="/opt"
SKIPSOURCECLONE=N
FEATURE_GATES="BlockVolume=true,PersistentLocalVolumes=true,LocalStorageCapacityIsolation=true,MountPropagation=true"
DEFAULT_STORAGECLASS=false
ENABLE_HOSTPATH=true
FAST_CLONE=N

# cinder env vars
CINDER_CLIENT=N
COS_AUTH_TYPE=noauth
CCINDERCLIENT_BYPASS_URL=http://172.18.14.146:8776/v3
COS_PROJECT_ID=admin
COS_VOLUME_API_VERSION=3.10


